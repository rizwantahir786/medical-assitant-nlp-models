{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f25cb3e-9efa-40b3-a69b-a25d2550c3db",
   "metadata": {},
   "source": [
    "<p id=\"eda\" style=\"font-size:30px; text-align:center; font-weight:bold\">BART (Bidirectional and Auto-Regressive Transformers)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df098be-7dba-4362-bc8f-64e082222df0",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c3022-4a80-4b75-977f-366bf5c7d537",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">BART is a model created by Facebook AI that uses transformers to work on both the encoder and decoder sides, like how GPT-2 and BERT do. BART combines the strengths of models like BERT, which are excellent at decoding coherent sequences of text with models like GPT-2, which are excellent at comprehending the context from supplied text (encoder tasks)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416d88c-e893-4771-a5cf-ea8ea2d97409",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px; font-weight:bold\"><u>Justification (Why used for medical chatbot (doctor-patient dialogues dataset))</u></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8182b44-f072-4edf-ab33-3da2bfa915e3",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">BART is a model that specialised at both comprehending and generating text. It excellent at taking details from conversations, especially because of its capacity to consider data from both the start and end of a dialogue. This ability enables it to produce accurate and relevant responses, which makes it an excellent choice for medical chatbots. Its versatility and ability to provide in-depth responses allow it to answer queries as well as write text, ensuring that patients receive information that will be precise and clear.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae9f4c-064f-4fc6-9bdf-48993178b7ae",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px; font-weight:bold\"><u>Version</u></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca18ae-93d7-4fe5-991e-5ef5faa74a0b",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">Facebook/bart-base, version has been used in this project for the training on patient-doctor dialogues. Facebook/bart-base has approximately 140 million parameters. The training time can be time consuming, but it can handle variety of tasks due its architecture</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157dcf49-6b4e-4ceb-9866-7a5c9d1950de",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:3px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2eb9b-780a-4f9e-a3c6-a800b9547cce",
   "metadata": {},
   "source": [
    "<p id=\"lib\" style=\"font-size:30px; text-align:center; font-weight:bold\">Required libraries or packages</p> <a href=\"#top\">Back To Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da6ad5a-6ff0-4bbb-b93f-9c7bc61ed251",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:3px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c05882-0ba0-4795-865a-54f218405b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 02:53:59.106561: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 02:53:59.988175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-09-06 02:53:59.988234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2023-09-06 02:53:59.988240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-09-06 02:54:01.706512: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-06 02:54:01.708225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-06 02:54:01.708984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import torch # PyTorch open-source deep learning framework\n",
    "import json # json library to load JSON data\n",
    "from sklearn.model_selection import train_test_split # train_test_split method from scikit learn for datset splitting \n",
    "\n",
    "from transformers import (\n",
    "   \n",
    "    TrainingArguments, # class to store arguments for training transformers models\n",
    "    Trainer,  # trainer class for training and evaluating transformers models\n",
    "    TrainerCallback, # case class for callbacks in the Trainer class\n",
    "    IntervalStrategy, # strategy to define when to run callbacks\n",
    "    BartTokenizer, # bart tokenizer\n",
    "    BartForConditionalGeneration, # bart model for text generation, specialised for text summarisation but can be used for answering questioning the problem I am solving\n",
    ")\n",
    "from nltk.translate.bleu_score import sentence_bleu # to calculate BLEU score\n",
    "from rouge import Rouge # to calculate ROUGE score\n",
    "from language_tool_python import LanguageTool# used to check grammar\n",
    "import spacy # library for natural language processing\n",
    "from transformers import EvalPrediction # used to store predictions and labels ids together\n",
    "import torch.nn as nn # to calculate loss\n",
    "torch.cuda.empty_cache() # clear cache from gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf57144-6421-49e7-a85d-2e04a97493ab",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2126c562-3bca-40f8-8f9a-b2ac4b41a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # check if GPU support available than use GPU otherwise use CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977598e-7cf8-4fcd-937c-85c4edae6eb2",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Load Dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1175f080-5843-432d-9d81-88a880456807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24711\n"
     ]
    }
   ],
   "source": [
    "with open(\"cleaned_medical_dialogues_dataset.json\", \"r\") as f: # load the data from the JSON file\n",
    "    data = json.load(f)\n",
    "\n",
    "data = data[::10] # sampling 1/10th of the dataset to manage time and computational resources\n",
    "\n",
    "print(len(data)) # print length number of samples in the sampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a818d8c-df4e-4d68-9be8-e9c8dbd016a6",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68168384-d095-4f94-a01c-14a8a4576abf",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Load Pre-trained Model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45404ab-7ae1-4098-8858-8a15a45e563b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a56b5-9524-4319-9459-5cb1e9fd21c3",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13f04b-e767-4fe7-8d54-69b51b903d4d",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Dataset Preparation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86637b84-19f8-487a-9d84-ff3db0573a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [item[\"Patient\"] for item in data] # extracting the Patient queries from the data and storing them in the 'inputs' list\n",
    "\n",
    "targets = [item[\"Doctor\"] for item in data] # extracting the Doctor responses from the data and storing them in the 'targets' list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e2fb2a-e087-4cb3-b853-ea77212df7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encodings = tokenizer(inputs, truncation=True, padding=True, return_tensors=\"pt\") # tokenizing the inputs using the tokenizer, truncating if they exceed the model's max length, padding them to the same length, and returning them as PyTorch tensors\n",
    "\n",
    "target_encodings = tokenizer(targets, truncation=True, padding=True, return_tensors=\"pt\") # tokenizing the targets using the tokenizer, truncating if they exceed the model's max length, padding them to the same length, and returning them as PyTorch tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb154711-f6da-48fb-b462-93bbbc7803f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalChatDataset(torch.utils.data.Dataset): # defining a PyTorch dataset class for the medical chat data\n",
    "    \n",
    "    # constructor method to store tokenized input and target  encodings\n",
    "    def __init__(self, input_encodings, target_encodings):\n",
    "        self.input_encodings = input_encodings\n",
    "        self.target_encodings = target_encodings\n",
    "\n",
    "    # method to fetch an item from the dataset given an index 'idx'\n",
    "    def __getitem__(self, idx):\n",
    "        # constructing a dictionary that contains input IDs, attention masks, and corresponding target responses\n",
    "        item = {\n",
    "            \"input_ids\": self.input_encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.input_encodings[\"attention_mask\"][idx], \n",
    "            \"labels\": self.target_encodings[\"input_ids\"][idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    # Method to return the total number of items in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.input_encodings[\"input_ids\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5f372e4-448b-432b-af4f-6f550c990064",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MedicalChatDataset(input_encodings, target_encodings) # calling the MedicalChatDataset class and returning the structured dataset required for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2c79ec-c4aa-4684-a133-70c1f0d19063",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de891d9b-e740-41d6-9074-e938d21e1a70",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Split Dataset</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6bb37-073d-41f1-ae60-54a5d310fc1d",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">\n",
    "  The training set and validation/test set are two sets that are typically separated from the available dataset in machine learning and deep learning.\n",
    "This separation helps in evaluating the model's performance on unseen data. The main goal is to prevent the model from overfitting the training set of data. If a model performs exceptionally well on training data but poorly on validation data, it is obviously overfitted.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56d3e517-3021-4ba8-b0d6-1be4ab9a744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2)  # 20% of data as validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfcd4d-5033-4fb5-8a44-d037693aa590",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">The parameter <b>test_size=0.2</b> indicates that 20% of the dataset will be used as the validation set, while the remaining 80% will be used for training.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db790b-7fda-4dc9-86d0-52e297415e89",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2fd57-88ec-49ce-875e-03da99c6c09f",
   "metadata": {},
   "source": [
    "<p id=\"lib\" style=\"font-size:30px; text-align:center; font-weight:bold\">Fine tuning facebook/bart-base</p> <a href=\"#top\">Back To Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102eb339-49ae-40c5-9cf0-baab5209d1f3",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb5783-f829-4f23-84c6-a0ccb650aeeb",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Define Early Stopping</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9cf4b-7c4a-4a97-a3a5-448ba4d0aff4",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">Callback function to halt the training process when there is no improvement in the model\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fdd5d5f-05ed-468c-b93f-5fc71fad8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience): # intialize the callback with number of epochs to wait\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.patience_counter = 0 # counter to keep track of epochs\n",
    "        self.best_score = None # store the best evaluation score\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        current_score = metrics.get(\"eval_loss\") # monitoring 'eval_loss'\n",
    "\n",
    "        if self.best_score is None or current_score < self.best_score: #compare the evaluation score and reset the patience counter\n",
    "            self.best_score = current_score\n",
    "            self.patience_counter = 0\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "\n",
    "        if self.patience_counter >= self.early_stopping_patience: # condition if the patient counter exceeds or equal than stop training \n",
    "            control.should_training_stop = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f81b38-d33f-4866-ad2f-60b33f65ca29",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f448d6-5c64-49f5-8d13-f28b0a7e8da9",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Define Training Arguments</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c533ffca-1bc8-4066-a0fc-d22439ba2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_bart_medical\", # saved model directory\n",
    "    per_device_train_batch_size=2, # batch size for each device, set to 2, because of the capacity of the system\n",
    "    gradient_accumulation_steps=8, # number of steps before performing a backpropagation\n",
    "    num_train_epochs=2, # number of training epochs, set to 2, due to limited time, this could also take days to train\n",
    "    logging_dir=\"./logs\", # directory to save logs\n",
    "    logging_steps=100, # interval to log details like loss\n",
    "    save_steps=1000, # interval to save the model \n",
    "    evaluation_strategy=\"steps\", # evaluate the model every specified number of steps\n",
    "    save_total_limit=3, # limit the number of saved models to the last 3\n",
    "    remove_unused_columns=False, # don't remove columns that aren't used by the model from the dataset \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fd591-b028-4fa2-b9ab-147ec6417128",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6dcfda-0741-49ba-8718-fdbfc9485c33",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Initialize  Trainer</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029ec305-48c6-4d97-a18f-17d6930e33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer( # initialize the Trainer instance \n",
    "    model=model, # passing the model to be fine tuned\n",
    "    args=training_args, # passing the training configurations\n",
    "    train_dataset=train_dataset,  # passing the training dataset\n",
    "    eval_dataset=val_dataset,  # passing the validation dataset\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)], # callback function for ealry stopping, with 2 epoch\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8304d79-333c-45bd-8282-12761a16f752",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e9da2-5a83-4be9-bee9-2ca92a3ffbae",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Train Model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7aa388ff-b9f5-4155-8108-b9f91399cff1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19768\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 2470\n",
      "  Number of trainable parameters = 139420416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2470' max='2470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2470/2470 54:45:07, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.171200</td>\n",
       "      <td>0.434019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.391237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.378523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.370626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.401200</td>\n",
       "      <td>0.364687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.359647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.386200</td>\n",
       "      <td>0.356392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.352636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.350098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.346687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.372600</td>\n",
       "      <td>0.344541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.342864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.342801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.339918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>0.339444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.338443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>0.337098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.336253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.335806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.343700</td>\n",
       "      <td>0.334405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>0.333904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.333421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>0.332907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.353700</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./finetuned_bart_medical/checkpoint-1000\n",
      "Configuration saved in ./finetuned_bart_medical/checkpoint-1000/config.json\n",
      "Model weights saved in ./finetuned_bart_medical/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./finetuned_bart_medical/checkpoint-2000\n",
      "Configuration saved in ./finetuned_bart_medical/checkpoint-2000/config.json\n",
      "Model weights saved in ./finetuned_bart_medical/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4943\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2470, training_loss=0.4841944783322724, metrics={'train_runtime': 197147.2414, 'train_samples_per_second': 0.201, 'train_steps_per_second': 0.013, 'total_flos': 2.410166272131072e+16, 'train_loss': 0.4841944783322724, 'epoch': 2.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() # training the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310a980-f99a-4e5f-80e8-1916a49df6e9",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a8642-6302-459c-bfd1-a1f7a22b40f9",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Save the model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3963e-4ec9-41a6-ae0e-ca4b5b7571ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./finetuned_bart_medical\") # save the trained model in the directory\n",
    "tokenizer.save_pretrained(\"./finetuned_bart_medical\") # save the tokenizer in the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bf11a-dbf0-4874-b391-1d39beb6a623",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429fff7-03e0-4b8a-b454-b1e7c7d1f72d",
   "metadata": {},
   "source": [
    "<p ><center><u style=\"font-size: 28px; margin-top: 10px; font-weight: bold\">Model Evaluation</u></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46be369-f7a0-401c-8fde-bfa3e0b9b45a",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">\n",
    "Model evaluation is an important part of creating machine learning models. It's about testing how good the model is using data it hasn't seen during training, usually called test or validation data. We do this to see if the model's answers are right and understand any mistakes it might make.\n",
    "</p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8901e04a-f9bf-4a76-a9cd-b976ad5d136b",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:1px; background-color:black\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b6550-6852-4065-a33b-805eeb384e62",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Load the model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a505c0b-7686-4e59-a915-1f7f6ee5023f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./finetuned_bart_medical/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file ./finetuned_bart_medical/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at ./finetuned_bart_medical.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\"./finetuned_bart_medical\").to(device)\n",
    "tokenizer = BartTokenizer.from_pretrained(\"./finetuned_bart_medical\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd7e48-09e3-4067-851e-62682ca81b1c",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\">Loss and Perplexity</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b47086-3f4c-4916-aecb-084c9ba96bdb",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">\n",
    "Loss measures the difference between a model's predictions and the actual data. It helps in adjusting the model to make better predictions. By looking at the loss, we can see if the model is improving and make necessary changes if needed.\n",
    "</p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d091e-889e-4e4c-a81a-2ac82d1e502d",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">\n",
    "    Perplexity checks how good a model is at guessing the next word. For medical chatbots, a lower value means the bot can chat more smoothly and make sense.\n",
    "</p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab613a-f77b-4aa2-9ddb-6bc918e56aba",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px; margin-top: 10px; font-weight: bold\">ROUGE score</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8259823d-c3ac-4e58-a202-8e0bb0fa2c60",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">\n",
    "    The ROUGE score looks at how much the predicted text matches the reference text using different measures like precision, recall, and F1-score. It's particularly useful for tasks like summarization to see how much key information the model includes in its output. In the context of medical chatbot, ROUGE can help determine how closely the generated response matches a desired or reference answer, indicating the system's ability to provide accurate and relevant information.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e9a463-106f-4062-8d3b-82ec0fbd3775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msc1/anaconda3/envs/Env-7145COMP/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "def compute_rouge(predictions, references):\n",
    "    return rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "\n",
    "def compute_metrics(eval_prediction: EvalPrediction):\n",
    "    logits_tuple = eval_prediction.predictions\n",
    "    labels = eval_prediction.label_ids\n",
    "    \n",
    "    # assuming the first tensor in the logits tuple is the actual logits tensor\n",
    "    logits = logits_tuple[0] if isinstance(logits_tuple, tuple) and len(logits_tuple) > 0 else None\n",
    "\n",
    "    # convert labels to tensor only if it's a numpy array\n",
    "    labels_tensor = torch.tensor(labels) if isinstance(labels, np.ndarray) else labels\n",
    "\n",
    "    # check if we successfully retrieved the logits tensor\n",
    "    if logits is None:\n",
    "        raise ValueError(\"Couldn't retrieve logits tensor from tuple.\")\n",
    "\n",
    "    # convert logits to a tensor\n",
    "    logits_tensor = torch.tensor(logits)\n",
    "\n",
    "    # calculate accuracy\n",
    "    predicted_indices = logits_tensor.argmax(dim=-1)\n",
    "    correct_predictions = (predicted_indices == labels_tensor).float()\n",
    "    accuracy = correct_predictions.mean().item()\n",
    "    \n",
    "    # calculate ROUGE scores\n",
    "    predicted_sentences = [tokenizer.decode(pred) for pred in predicted_indices]\n",
    "    reference_sentences = [tokenizer.decode(label) for label in labels_tensor]\n",
    "    rouge_scores = compute_rouge(predicted_sentences, reference_sentences)\n",
    "\n",
    "    # calculate the loss and perplexity\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(logits_tensor.view(-1, logits_tensor.shape[-1]), labels_tensor.view(-1))\n",
    "    perplexity = torch.exp(loss)\n",
    "\n",
    "    results = {\n",
    "        \"loss\": loss.item(),\n",
    "        \"perplexity\": perplexity.item(),\n",
    "        \"accuracy\": accuracy,\n",
    "        \"rouge-1\": {\n",
    "            \"r\": rouge_scores['rouge1'].mid.recall,\n",
    "            \"p\": rouge_scores['rouge1'].mid.precision,\n",
    "            \"f\": rouge_scores['rouge1'].mid.fmeasure\n",
    "        },\n",
    "        \"rouge-2\": {\n",
    "            \"r\": rouge_scores['rouge2'].mid.recall,\n",
    "            \"p\": rouge_scores['rouge2'].mid.precision,\n",
    "            \"f\": rouge_scores['rouge2'].mid.fmeasure\n",
    "        },\n",
    "        \"rouge-l\": {\n",
    "            \"r\": rouge_scores['rougeL'].mid.recall,\n",
    "            \"p\": rouge_scores['rougeL'].mid.precision,\n",
    "            \"f\": rouge_scores['rougeL'].mid.fmeasure\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19544df6-9bde-4643-a182-334c34c48bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_val_dataset = val_dataset[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83a413f1-849e-41fb-84b2-975871254037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_eval_batch_size=1,\n",
    "    output_dir=\"./finetuned_bart_medical\",\n",
    "    do_train=False,  # passing false so it will be only used for evaluation\n",
    "    do_eval=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=subset_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f850c10f-d7cf-494a-a39b-487e6e7e1d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'r': 0.9468766505347077, 'p': 0.9548108608335324, 'f': 0.9509627198974746}\" of type <class 'dict'> for key \"eval/rouge-1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'r': 0.9114312029118358, 'p': 0.9188992264672378, 'f': 0.9152093838027202}\" of type <class 'dict'> for key \"eval/rouge-2\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'r': 0.9337740161718167, 'p': 0.9415215814681496, 'f': 0.9377553840850238}\" of type <class 'dict'> for key \"eval/rouge-l\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3937792479991913, 'eval_perplexity': 1.4825732707977295, 'eval_accuracy': 0.9208984375, 'eval_rouge-1': {'r': 0.9468766505347077, 'p': 0.9548108608335324, 'f': 0.9509627198974746}, 'eval_rouge-2': {'r': 0.9114312029118358, 'p': 0.9188992264672378, 'f': 0.9152093838027202}, 'eval_rouge-l': {'r': 0.9337740161718167, 'p': 0.9415215814681496, 'f': 0.9377553840850238}, 'eval_runtime': 11.8078, 'eval_samples_per_second': 0.847, 'eval_steps_per_second': 0.847}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c10c122e-0a32-4902-ba9f-412a4828c583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3937792479991913,\n",
       " 'eval_perplexity': 1.4825732707977295,\n",
       " 'eval_accuracy': 0.9208984375,\n",
       " 'eval_rouge-1': {'r': 0.9468766505347077,\n",
       "  'p': 0.9548108608335324,\n",
       "  'f': 0.9509627198974746},\n",
       " 'eval_rouge-2': {'r': 0.9114312029118358,\n",
       "  'p': 0.9188992264672378,\n",
       "  'f': 0.9152093838027202},\n",
       " 'eval_rouge-l': {'r': 0.9337740161718167,\n",
       "  'p': 0.9415215814681496,\n",
       "  'f': 0.9377553840850238},\n",
       " 'eval_runtime': 11.8078,\n",
       " 'eval_samples_per_second': 0.847,\n",
       " 'eval_steps_per_second': 0.847}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb85e918-c5eb-43c8-9766-f8a65bc08252",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\"><u>Saving Results to the dataframe</u></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd72234-d3d0-4f46-abbf-0885fbe74336",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20px\">\n",
    "  I am saving the results in the dataframe one by one of each model so i can compare the results in the separate python file (medical_chatbot_eval_metrics.ipynb).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed7b7de7-7b9c-4135-8b42-3603e0f26ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics_results = {\n",
    "    'model_name': 'Facebook/BART-base',\n",
    "    'loss': eval_results['eval_loss'],\n",
    "    'perplexity': eval_results['eval_perplexity'],\n",
    "    'accuracy': eval_results['eval_accuracy'],\n",
    "    'rouge-1_r': eval_results['eval_rouge-1']['r'],\n",
    "    'rouge-1_p': eval_results['eval_rouge-1']['p'],\n",
    "    'rouge-1_f': eval_results['eval_rouge-1']['f'],\n",
    "    'rouge-2_r': eval_results['eval_rouge-2']['r'],\n",
    "    'rouge-2_p': eval_results['eval_rouge-2']['p'],\n",
    "    'rouge-2_f': eval_results['eval_rouge-2']['f'],\n",
    "    'rouge-l_r': eval_results['eval_rouge-l']['r'],\n",
    "    'rouge-l_p': eval_results['eval_rouge-l']['p'],\n",
    "    'rouge-l_f': eval_results['eval_rouge-l']['f']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9787c5-5b60-46b6-9423-8c3713ede25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38cffc75-0db2-4056-af17-ce047a01c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "242e9855-f891-409a-9f04-075d239d638c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>rouge-1_r</th>\n",
       "      <th>rouge-1_p</th>\n",
       "      <th>rouge-1_f</th>\n",
       "      <th>rouge-2_r</th>\n",
       "      <th>rouge-2_p</th>\n",
       "      <th>rouge-2_f</th>\n",
       "      <th>rouge-l_r</th>\n",
       "      <th>rouge-l_p</th>\n",
       "      <th>rouge-l_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Encoder-Decoder LSTM</td>\n",
       "      <td>0.074382</td>\n",
       "      <td>1.052910</td>\n",
       "      <td>0.990507</td>\n",
       "      <td>0.985153</td>\n",
       "      <td>0.967791</td>\n",
       "      <td>0.976377</td>\n",
       "      <td>0.975947</td>\n",
       "      <td>0.946462</td>\n",
       "      <td>0.960935</td>\n",
       "      <td>0.985153</td>\n",
       "      <td>0.967791</td>\n",
       "      <td>0.976377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-2 Medium</td>\n",
       "      <td>10.379869</td>\n",
       "      <td>32204.726562</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.497472</td>\n",
       "      <td>0.526547</td>\n",
       "      <td>0.511501</td>\n",
       "      <td>0.176954</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>0.181735</td>\n",
       "      <td>0.388866</td>\n",
       "      <td>0.411154</td>\n",
       "      <td>0.399379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name       loss    perplexity  accuracy  rouge-1_r  \\\n",
       "0  Encoder-Decoder LSTM   0.074382      1.052910  0.990507   0.985153   \n",
       "1          GPT-2 Medium  10.379869  32204.726562  0.009531   0.497472   \n",
       "\n",
       "   rouge-1_p  rouge-1_f  rouge-2_r  rouge-2_p  rouge-2_f  rouge-l_r  \\\n",
       "0   0.967791   0.976377   0.975947   0.946462   0.960935   0.985153   \n",
       "1   0.526547   0.511501   0.176954   0.186899   0.181735   0.388866   \n",
       "\n",
       "   rouge-l_p  rouge-l_f  \n",
       "0   0.967791   0.976377  \n",
       "1   0.411154   0.399379  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics_results_dataframe = pd.read_csv('eval_metrics_results_dataframe.csv') # load the csv  \n",
    "eval_metrics_results_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "143c20e4-5ca1-446d-baaf-a4f02b9936b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>rouge-1_r</th>\n",
       "      <th>rouge-1_p</th>\n",
       "      <th>rouge-1_f</th>\n",
       "      <th>rouge-2_r</th>\n",
       "      <th>rouge-2_p</th>\n",
       "      <th>rouge-2_f</th>\n",
       "      <th>rouge-l_r</th>\n",
       "      <th>rouge-l_p</th>\n",
       "      <th>rouge-l_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Encoder-Decoder LSTM</td>\n",
       "      <td>0.074382</td>\n",
       "      <td>1.052910</td>\n",
       "      <td>0.990507</td>\n",
       "      <td>0.985153</td>\n",
       "      <td>0.967791</td>\n",
       "      <td>0.976377</td>\n",
       "      <td>0.975947</td>\n",
       "      <td>0.946462</td>\n",
       "      <td>0.960935</td>\n",
       "      <td>0.985153</td>\n",
       "      <td>0.967791</td>\n",
       "      <td>0.976377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-2 Medium</td>\n",
       "      <td>10.379869</td>\n",
       "      <td>32204.726562</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.497472</td>\n",
       "      <td>0.526547</td>\n",
       "      <td>0.511501</td>\n",
       "      <td>0.176954</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>0.181735</td>\n",
       "      <td>0.388866</td>\n",
       "      <td>0.411154</td>\n",
       "      <td>0.399379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook/BART-base</td>\n",
       "      <td>0.393779</td>\n",
       "      <td>1.482573</td>\n",
       "      <td>0.920898</td>\n",
       "      <td>0.946877</td>\n",
       "      <td>0.954811</td>\n",
       "      <td>0.950963</td>\n",
       "      <td>0.911431</td>\n",
       "      <td>0.918899</td>\n",
       "      <td>0.915209</td>\n",
       "      <td>0.933774</td>\n",
       "      <td>0.941522</td>\n",
       "      <td>0.937755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name       loss    perplexity  accuracy  rouge-1_r  \\\n",
       "0  Encoder-Decoder LSTM   0.074382      1.052910  0.990507   0.985153   \n",
       "1          GPT-2 Medium  10.379869  32204.726562  0.009531   0.497472   \n",
       "2    Facebook/BART-base   0.393779      1.482573  0.920898   0.946877   \n",
       "\n",
       "   rouge-1_p  rouge-1_f  rouge-2_r  rouge-2_p  rouge-2_f  rouge-l_r  \\\n",
       "0   0.967791   0.976377   0.975947   0.946462   0.960935   0.985153   \n",
       "1   0.526547   0.511501   0.176954   0.186899   0.181735   0.388866   \n",
       "2   0.954811   0.950963   0.911431   0.918899   0.915209   0.933774   \n",
       "\n",
       "   rouge-l_p  rouge-l_f  \n",
       "0   0.967791   0.976377  \n",
       "1   0.411154   0.399379  \n",
       "2   0.941522   0.937755  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics_results_dataframe = eval_metrics_results_dataframe.append(eval_metrics_results, ignore_index=True) # append the record in the dataframe\n",
    "eval_metrics_results_dataframe.to_csv('eval_metrics_results_dataframe.csv', index=False) # save to the same file\n",
    "eval_metrics_results_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d35aed-fc7f-4e17-aaa6-021fbe2011f9",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 23px; margin-top: 10px; font-weight: bold\"><u>Answer to user queries by using the model</u></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14523944-fc85-4e94-a022-214d73365951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    # encode the user input and return tensor in PyTorch format\n",
    "    input_tensor = tokenizer.encode(user_input, return_tensors=\"pt\")\n",
    "    \n",
    "    # generate a response from the model\n",
    "    output_tensor = model.generate(input_tensor, max_length=150, num_beams=5, early_stopping=True)\n",
    "    \n",
    "    # decode the response\n",
    "    response = tokenizer.decode(output_tensor[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5afdea9-7b58-4247-94d3-4f9f276c4b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is flu?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  hello and welcome to ask a doctor service. i have reviewed your query and here is my advice.  flu is a viral illness. it is caused by a viral infection. it can be treated with antibiotics.  hope i have answered your query. let me know if i can assist you further.  regards, dr. shinas hussain, general  family physician \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "# Chat loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "        break\n",
    "    response = generate_response(user_input)\n",
    "    print(\"Bot: \", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
